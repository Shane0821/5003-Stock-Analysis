apiVersion: v1
kind: ServiceAccount
metadata:
  name: spark
  namespace: default
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: spark-pod-creator
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["create", "get", "watch", "list", "delete", "patch", "update", "deletecollection"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: spark-pod-creator-binding
  namespace: default
subjects:
- kind: ServiceAccount
  name: spark
  namespace: default
roleRef:
  kind: Role
  name: spark-pod-creator
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose.yml
    kompose.version: 1.26.0 (40646f47)
  creationTimestamp: null
  labels:
    io.kompose.service: spark
  name: spark
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: spark
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose.yml
        kompose.version: 1.26.0 (40646f47)
      creationTimestamp: null
      labels:
        io.kompose.service: spark
    spec:
      serviceAccountName: spark
      containers:
        - image: shane233/k8s-spark:latest
          name: spark
          resources: {}
          imagePullPolicy: Always
          command:
            - /bin/bash
            - -c
            - |
              /opt/spark/bin/spark-submit \
              --master k8s://https://kubernetes.default.svc:443 \
              --deploy-mode cluster \
              --name spark-streaming \
              --conf spark.executor.instances=4 \
              --conf spark.kubernetes.driver.container.image=shane233/k8s-spark:latest \
              --conf spark.kubernetes.executor.container.image=spark:3.4.1 \
              --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
              --conf spark.kubernetes.authenticate.executor.serviceAccountName=spark \
              --conf spark.kubernetes.driver.cores=2 \
              --conf spark.kubernetes.executor.cores=2 \
              --conf spark.kubernetes.driver.memory=4GB \
              --conf spark.kubernetes.executor.memory=4GB \
              --conf spark.jars.ivy=/tmp/.ivy \
              --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,org.mongodb.spark:mongo-spark-connector_2.12:10.2.1 \
              local:///opt/spark/code/streaming_processor.py
status: {}
